{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2de62d4a",
   "metadata": {},
   "source": [
    "## Modeling Using Only Year and Odometer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb0d54f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf9051f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 375619 #number of records in file\n",
    "s = 10000 #desired sample size\n",
    "filename = '../data/clean/df1.csv'\n",
    "skip = sorted(random.sample(range(1,n+1),n-s))\n",
    "df=pd.read_csv(filename, header=0, skiprows=skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9350c9af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 21)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5de8382e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['state_area', 'price', 'year', 'manufacturer', 'model', 'condition',\n",
       "       'cylinders', 'fuel', 'odometer', 'title', 'transmission', 'drive',\n",
       "       'size', 'type', 'color', 'posting_date', 'State', 'region', 'division',\n",
       "       'VIN_p', 'image_url_p'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aed698fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target object and call it y\n",
    "y = df['price']\n",
    "# Create X\n",
    "features = ['year','odometer']\n",
    "X = df[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f52b69",
   "metadata": {},
   "source": [
    "### DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f17be7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into validation and training data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba19dacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(random_state=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify Model\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "# Fit Model\n",
    "dtr.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c81d42f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE: 9,280\n"
     ]
    }
   ],
   "source": [
    "val_predictions = dtr.predict(val_X)\n",
    "val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "print(\"Validation MAE: {:,.0f}\".format(val_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6648939d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, preds_val)\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "234b756a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "candidate_max_leaf_nodes = [5, 25, 50, 100, 250, 500]\n",
    "# Write loop to find the ideal tree size from candidate_max_leaf_nodes\n",
    "scores = {leaf_size: get_mae(leaf_size, train_X, val_X, train_y, val_y) for leaf_size in candidate_max_leaf_nodes}\n",
    "best_tree_size = min(scores, key=scores.get)\n",
    "\n",
    "# Store the best value of max_leaf_nodes (it will be either 5, 25, 50, 100, 250 or 500)\n",
    "print(best_tree_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35da9afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_leaf_nodes=5, random_state=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill in argument to make optimal size and uncomment\n",
    "final_model = DecisionTreeRegressor(max_leaf_nodes=5, random_state=1)\n",
    "\n",
    "# fit the final model and uncomment the next two lines\n",
    "final_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2f49944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE: 8,890\n"
     ]
    }
   ],
   "source": [
    "val_predictions = final_model.predict(val_X)\n",
    "val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "print(\"Validation MAE: {:,.0f}\".format(val_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4cb00c",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "060cb068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE for Random Forest Model: 8407.30112552554\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define the model. Set random_state to 1\n",
    "rf_model = RandomForestRegressor(random_state=1)\n",
    "\n",
    "# fit your model\n",
    "rf_model.fit(train_X, train_y)\n",
    "\n",
    "# Calculate the mean absolute error of your Random Forest model on the validation data\n",
    "rf_val_predictions = rf_model.predict(val_X)\n",
    "rf_val_mae = mean_absolute_error(rf_val_predictions, val_y)\n",
    "\n",
    "print(\"Validation MAE for Random Forest Model: {}\".format(rf_val_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d21a32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "799bfd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define the models\n",
    "model_1 = RandomForestRegressor(n_estimators=50, random_state=0)\n",
    "model_2 = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "model_3 = RandomForestRegressor(n_estimators=100, criterion='mae', random_state=0)\n",
    "model_4 = RandomForestRegressor(n_estimators=200, min_samples_split=20, random_state=0)\n",
    "model_5 = RandomForestRegressor(n_estimators=100, max_depth=7, random_state=0)\n",
    "\n",
    "models = [model_1, model_2, model_3, model_4, model_5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e8acee",
   "metadata": {},
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Function for comparing different models\n",
    "def score_model(model, X_t=X_train, X_v=X_valid, y_t=y_train, y_v=y_valid):\n",
    "    model.fit(X_t, y_t)\n",
    "    preds = model.predict(X_v)\n",
    "    return mean_absolute_error(y_v, preds)\n",
    "\n",
    "for i in range(0, len(models)):\n",
    "    mae = score_model(models[i])\n",
    "    print(\"Model %d MAE: %d\" % (i+1, mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e87848",
   "metadata": {},
   "source": [
    "## Modeling With Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbcc8e46",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state_area         0\n",
       "division           0\n",
       "region             0\n",
       "State              0\n",
       "posting_date       0\n",
       "VIN_p              0\n",
       "odometer           0\n",
       "image_url_p        0\n",
       "year               0\n",
       "price              0\n",
       "transmission      29\n",
       "fuel              53\n",
       "model            112\n",
       "title            162\n",
       "manufacturer     241\n",
       "color           1207\n",
       "type            1284\n",
       "condition       1849\n",
       "drive           2283\n",
       "cylinders       3768\n",
       "size            6856\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "351127c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state_area      0\n",
       "division        0\n",
       "region          0\n",
       "State           0\n",
       "posting_date    0\n",
       "color           0\n",
       "type            0\n",
       "size            0\n",
       "drive           0\n",
       "VIN_p           0\n",
       "transmission    0\n",
       "odometer        0\n",
       "fuel            0\n",
       "cylinders       0\n",
       "condition       0\n",
       "model           0\n",
       "manufacturer    0\n",
       "year            0\n",
       "price           0\n",
       "title           0\n",
       "image_url_p     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fill na with mode\n",
    "df=df.fillna(df.mode().iloc[0])\n",
    "df.isna().sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da7db6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_to_dummy=df[['price','odometer','manufacturer', 'model', 'condition',\n",
    "       'cylinders', 'size','fuel','title', 'transmission', 'drive', 'type', 'color','State']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27262f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['price', 'year', 'odometer', 'VIN_p', 'image_url_p',\n",
      "       'state_area_abilene', 'state_area_akron / canton', 'state_area_albany',\n",
      "       'state_area_albuquerque', 'state_area_altoona-johnstown',\n",
      "       ...\n",
      "       'region_South', 'region_West', 'division_East South Central',\n",
      "       'division_Middle Atlantic', 'division_Mountain', 'division_New England',\n",
      "       'division_Pacific', 'division_South Atlantic',\n",
      "       'division_West North Central', 'division_West South Central'],\n",
      "      dtype='object', length=13933)\n"
     ]
    }
   ],
   "source": [
    "df1_final = pd.get_dummies(df, drop_first=True)\n",
    "print(df1_final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c41815d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>odometer</th>\n",
       "      <th>VIN_p</th>\n",
       "      <th>image_url_p</th>\n",
       "      <th>state_area_abilene</th>\n",
       "      <th>state_area_akron / canton</th>\n",
       "      <th>state_area_albany</th>\n",
       "      <th>state_area_albuquerque</th>\n",
       "      <th>state_area_altoona-johnstown</th>\n",
       "      <th>...</th>\n",
       "      <th>region_South</th>\n",
       "      <th>region_West</th>\n",
       "      <th>division_East South Central</th>\n",
       "      <th>division_Middle Atlantic</th>\n",
       "      <th>division_Mountain</th>\n",
       "      <th>division_New England</th>\n",
       "      <th>division_Pacific</th>\n",
       "      <th>division_South Atlantic</th>\n",
       "      <th>division_West North Central</th>\n",
       "      <th>division_West South Central</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3902</th>\n",
       "      <td>15590</td>\n",
       "      <td>2016</td>\n",
       "      <td>53066</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3662</th>\n",
       "      <td>7100</td>\n",
       "      <td>2007</td>\n",
       "      <td>150200</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9566</th>\n",
       "      <td>24997</td>\n",
       "      <td>2017</td>\n",
       "      <td>46564</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>3000</td>\n",
       "      <td>1998</td>\n",
       "      <td>144000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3505</th>\n",
       "      <td>5695</td>\n",
       "      <td>2009</td>\n",
       "      <td>140852</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4671</th>\n",
       "      <td>21990</td>\n",
       "      <td>2018</td>\n",
       "      <td>51773</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7082</th>\n",
       "      <td>5495</td>\n",
       "      <td>2003</td>\n",
       "      <td>90000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5902</th>\n",
       "      <td>45999</td>\n",
       "      <td>2018</td>\n",
       "      <td>72234</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9232</th>\n",
       "      <td>29990</td>\n",
       "      <td>2017</td>\n",
       "      <td>31622</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9784</th>\n",
       "      <td>37590</td>\n",
       "      <td>2015</td>\n",
       "      <td>62718</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5978</th>\n",
       "      <td>43999</td>\n",
       "      <td>2020</td>\n",
       "      <td>26545</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6766</th>\n",
       "      <td>3995</td>\n",
       "      <td>2009</td>\n",
       "      <td>186850</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8340</th>\n",
       "      <td>27995</td>\n",
       "      <td>2019</td>\n",
       "      <td>9549</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3112</th>\n",
       "      <td>25820</td>\n",
       "      <td>2016</td>\n",
       "      <td>88513</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2316</th>\n",
       "      <td>8400</td>\n",
       "      <td>2014</td>\n",
       "      <td>160070</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 13933 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  year  odometer  VIN_p  image_url_p  state_area_abilene  \\\n",
       "3902  15590  2016     53066   True         True                   0   \n",
       "3662   7100  2007    150200   True         True                   0   \n",
       "9566  24997  2017     46564   True         True                   0   \n",
       "747    3000  1998    144000   True         True                   0   \n",
       "3505   5695  2009    140852   True         True                   0   \n",
       "4671  21990  2018     51773   True         True                   0   \n",
       "7082   5495  2003     90000   True         True                   0   \n",
       "5902  45999  2018     72234   True         True                   0   \n",
       "9232  29990  2017     31622   True         True                   0   \n",
       "9784  37590  2015     62718   True         True                   0   \n",
       "5978  43999  2020     26545   True         True                   0   \n",
       "6766   3995  2009    186850   True         True                   0   \n",
       "8340  27995  2019      9549   True         True                   0   \n",
       "3112  25820  2016     88513   True         True                   0   \n",
       "2316   8400  2014    160070   True         True                   0   \n",
       "\n",
       "      state_area_akron / canton  state_area_albany  state_area_albuquerque  \\\n",
       "3902                          0                  0                       0   \n",
       "3662                          0                  0                       0   \n",
       "9566                          0                  0                       0   \n",
       "747                           0                  0                       0   \n",
       "3505                          0                  0                       0   \n",
       "4671                          0                  0                       0   \n",
       "7082                          0                  0                       0   \n",
       "5902                          0                  0                       0   \n",
       "9232                          0                  0                       0   \n",
       "9784                          0                  0                       0   \n",
       "5978                          0                  0                       0   \n",
       "6766                          0                  0                       0   \n",
       "8340                          0                  0                       0   \n",
       "3112                          0                  0                       0   \n",
       "2316                          0                  0                       0   \n",
       "\n",
       "      state_area_altoona-johnstown  ...  region_South  region_West  \\\n",
       "3902                             0  ...             0            1   \n",
       "3662                             0  ...             0            0   \n",
       "9566                             0  ...             1            0   \n",
       "747                              0  ...             1            0   \n",
       "3505                             0  ...             0            0   \n",
       "4671                             0  ...             0            1   \n",
       "7082                             0  ...             1            0   \n",
       "5902                             0  ...             0            1   \n",
       "9232                             0  ...             1            0   \n",
       "9784                             0  ...             1            0   \n",
       "5978                             0  ...             0            1   \n",
       "6766                             0  ...             1            0   \n",
       "8340                             0  ...             0            0   \n",
       "3112                             0  ...             1            0   \n",
       "2316                             0  ...             0            0   \n",
       "\n",
       "      division_East South Central  division_Middle Atlantic  \\\n",
       "3902                            0                         0   \n",
       "3662                            0                         0   \n",
       "9566                            1                         0   \n",
       "747                             0                         0   \n",
       "3505                            0                         0   \n",
       "4671                            0                         0   \n",
       "7082                            0                         0   \n",
       "5902                            0                         0   \n",
       "9232                            0                         0   \n",
       "9784                            0                         0   \n",
       "5978                            0                         0   \n",
       "6766                            1                         0   \n",
       "8340                            0                         1   \n",
       "3112                            0                         0   \n",
       "2316                            0                         1   \n",
       "\n",
       "      division_Mountain  division_New England  division_Pacific  \\\n",
       "3902                  0                     0                 1   \n",
       "3662                  0                     0                 0   \n",
       "9566                  0                     0                 0   \n",
       "747                   0                     0                 0   \n",
       "3505                  0                     0                 0   \n",
       "4671                  0                     0                 1   \n",
       "7082                  0                     0                 0   \n",
       "5902                  1                     0                 0   \n",
       "9232                  0                     0                 0   \n",
       "9784                  0                     0                 0   \n",
       "5978                  1                     0                 0   \n",
       "6766                  0                     0                 0   \n",
       "8340                  0                     0                 0   \n",
       "3112                  0                     0                 0   \n",
       "2316                  0                     0                 0   \n",
       "\n",
       "      division_South Atlantic  division_West North Central  \\\n",
       "3902                        0                            0   \n",
       "3662                        0                            0   \n",
       "9566                        0                            0   \n",
       "747                         1                            0   \n",
       "3505                        0                            0   \n",
       "4671                        0                            0   \n",
       "7082                        1                            0   \n",
       "5902                        0                            0   \n",
       "9232                        1                            0   \n",
       "9784                        1                            0   \n",
       "5978                        0                            0   \n",
       "6766                        0                            0   \n",
       "8340                        0                            0   \n",
       "3112                        0                            0   \n",
       "2316                        0                            0   \n",
       "\n",
       "      division_West South Central  \n",
       "3902                            0  \n",
       "3662                            0  \n",
       "9566                            0  \n",
       "747                             0  \n",
       "3505                            0  \n",
       "4671                            0  \n",
       "7082                            0  \n",
       "5902                            0  \n",
       "9232                            0  \n",
       "9784                            0  \n",
       "5978                            0  \n",
       "6766                            0  \n",
       "8340                            0  \n",
       "3112                            1  \n",
       "2316                            0  \n",
       "\n",
       "[15 rows x 13933 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_final.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48cb9963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target object and call it y\n",
    "y = df1_final.price\n",
    "# Create X\n",
    "X = df1_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0ac5a42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['price', 'year', 'odometer', 'VIN_p', 'image_url_p',\n",
       "       'state_area_abilene', 'state_area_akron / canton', 'state_area_albany',\n",
       "       'state_area_albuquerque', 'state_area_altoona-johnstown',\n",
       "       ...\n",
       "       'region_South', 'region_West', 'division_East South Central',\n",
       "       'division_Middle Atlantic', 'division_Mountain', 'division_New England',\n",
       "       'division_Pacific', 'division_South Atlantic',\n",
       "       'division_West North Central', 'division_West South Central'],\n",
       "      dtype='object', length=13933)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfc5010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(['price'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a81e6cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'odometer', 'VIN_p', 'image_url_p', 'state_area_abilene',\n",
       "       'state_area_akron / canton', 'state_area_albany',\n",
       "       'state_area_albuquerque', 'state_area_altoona-johnstown',\n",
       "       'state_area_amarillo',\n",
       "       ...\n",
       "       'region_South', 'region_West', 'division_East South Central',\n",
       "       'division_Middle Atlantic', 'division_Mountain', 'division_New England',\n",
       "       'division_Pacific', 'division_South Atlantic',\n",
       "       'division_West North Central', 'division_West South Central'],\n",
       "      dtype='object', length=13932)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbac6b06",
   "metadata": {},
   "source": [
    "### DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4d3d8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into validation and training data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86a134ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(random_state=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify Model\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "# Fit Model\n",
    "dtr.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bcabced7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE: 5,499\n"
     ]
    }
   ],
   "source": [
    "val_predictions = dtr.predict(val_X)\n",
    "val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "print(\"Validation MAE: {:,.0f}\".format(val_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3aba2b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, preds_val)\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6c2c5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "candidate_max_leaf_nodes = [5, 25, 50, 100, 250, 500]\n",
    "# Write loop to find the ideal tree size from candidate_max_leaf_nodes\n",
    "scores = {leaf_size: get_mae(leaf_size, train_X, val_X, train_y, val_y) for leaf_size in candidate_max_leaf_nodes}\n",
    "best_tree_size = min(scores, key=scores.get)\n",
    "\n",
    "# Store the best value of max_leaf_nodes (it will be either 5, 25, 50, 100, 250 or 500)\n",
    "print(best_tree_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c346a364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_leaf_nodes=500, random_state=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill in argument to make optimal size and uncomment\n",
    "final_model = DecisionTreeRegressor(max_leaf_nodes=500, random_state=1)\n",
    "\n",
    "# fit the final model and uncomment the next two lines\n",
    "final_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e719e041",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE: 3,519\n"
     ]
    }
   ],
   "source": [
    "val_predictions = final_model.predict(val_X)\n",
    "val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "print(\"Validation MAE: {:,.0f}\".format(val_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1382996a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\alw-hp-17\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "D:\\Users\\alw-hp-17\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "D:\\Users\\alw-hp-17\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "D:\\Users\\alw-hp-17\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "D:\\Users\\alw-hp-17\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Instantiate a ridge regressor: ridge\n",
    "ridge = Ridge(alpha=0.5, normalize=True)\n",
    "\n",
    "# Perform 5-fold cross-validation: ridge_cv\n",
    "ridge_cv = cross_val_score(ridge, X, y, cv=5)\n",
    "\n",
    "# Print the cross-validated scores\n",
    "print(ridge_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed74993f",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5a3d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define the model. Set random_state to 1\n",
    "rf_model = RandomForestRegressor(random_state=1)\n",
    "\n",
    "# fit your model\n",
    "rf_model.fit(train_X, train_y)\n",
    "\n",
    "# Calculate the mean absolute error of your Random Forest model on the validation data\n",
    "rf_val_predictions = rf_model.predict(val_X)\n",
    "rf_val_mae = mean_absolute_error(rf_val_predictions, val_y)\n",
    "\n",
    "print(\"Validation MAE for Random Forest Model: {}\".format(rf_val_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7215e7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b4dddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define the models\n",
    "model_1 = RandomForestRegressor(n_estimators=50, random_state=0)\n",
    "model_2 = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "model_3 = RandomForestRegressor(n_estimators=100, criterion='mae', random_state=0)\n",
    "model_4 = RandomForestRegressor(n_estimators=200, min_samples_split=20, random_state=0)\n",
    "model_5 = RandomForestRegressor(n_estimators=100, max_depth=7, random_state=0)\n",
    "\n",
    "models = [model_1, model_2, model_3, model_4, model_5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af035ad",
   "metadata": {},
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Function for comparing different models\n",
    "def score_model(model, X_t=X_train, X_v=X_valid, y_t=y_train, y_v=y_valid):\n",
    "    model.fit(X_t, y_t)\n",
    "    preds = model.predict(X_v)\n",
    "    return mean_absolute_error(y_v, preds)\n",
    "\n",
    "for i in range(0, len(models)):\n",
    "    mae = score_model(models[i])\n",
    "    print(\"Model %d MAE: %d\" % (i+1, mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a37232",
   "metadata": {},
   "source": [
    "## Pre-processing and training data development\n",
    "Standardize and train your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6b5ed1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate correlation matrix\n",
    "corr = df.corr()# plot the heatmap\n",
    "sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, annot=True, cmap=sns.diverging_palette(220, 20, as_cmap=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8fd02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features=df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51057b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder=LabelEncoder()\n",
    "encoded=df[cat_features].apply(encoder.fit_transform)\n",
    "dfud=df.drop(cat_features,axis=1)\n",
    "dfuc=pd.concat([encoded,dfud],axis=1)\n",
    "dfuc.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddfbfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate correlation matrix\n",
    "sns.set(style='white')\n",
    "corr = dfuc.drop(columns=['VIN_p','image_url_p']).corr()# plot the heatmap\n",
    "mask=np.zeros_like(corr,dtype=bool)\n",
    "mask[np.triu_indices_from(mask)]=True\n",
    "f,ax=plt.subplots(figsize=(18,15))\n",
    "cmap=sns.diverging_palette(220,10,as_cmap=True)\n",
    "sns.heatmap(corr, mask=mask,cmap=cmap,xticklabels=corr.columns, yticklabels=corr.columns, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9e6c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_head = df1_final.iloc[:, df1_final.columns != 'price']\n",
    "X = df1_final.loc[:, df1_final.columns != 'price']\n",
    "y = df1_final['price']\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f900e105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=0)\n",
    "model = RandomForestRegressor(random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d8fbab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(mae(y_test, pred))\n",
    "print(df1_final['price'].mean())\n",
    "print(model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3405665a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We chose Random Forest algorith for this project\n",
    "#Let's do Cross Validation to check the overal score in the Training Set\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "scores = []\n",
    "forest = RandomForestRegressor(n_estimators=20, random_state=0)\n",
    "acc = cross_val_score(forest, X_train, y_train, scoring='r2', cv=5)\n",
    "scores.append(round(acc.mean()*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b3902f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Metrics': ['R2'],\n",
    "    'Accuracy': scores})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181d45ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feat_importances = pd.Series(model.feature_importances_, index=X_head.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh',figsize=(10,10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
